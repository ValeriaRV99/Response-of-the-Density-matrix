{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d35e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ase.build import molecule\n",
    "from ase.visualize import view\n",
    "import sys\n",
    "sys.path.insert(0,\"/home/valeria/Documents/DFTPY/PseudoP/vg/pyscf\")\n",
    "from pyscf.pbc.tools.pyscf_ase import atoms_from_ase\n",
    "from pyscf import gto,dft\n",
    "import matplotlib.pyplot as plt\n",
    "from pyscf import scf\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4d27e",
   "metadata": {},
   "source": [
    "#### Porpose of thi code\n",
    "To model the effect of an external potential, we begin by generating the density matrix of a water molecule and 1000 external potentials. The application of each potential induces a change in the density matrix, which we express through the mapping:\n",
    "$$\n",
    "\\delta \\gamma \\leftrightarrow \\delta v\n",
    "$$\n",
    "This enables us to investigate the relationship between changes in the external potential and changes in the density matrix. We can learn this relationship using machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009e7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = molecule('H2O')\n",
    "basis = 'sto-3g'#'6-31g*'\n",
    "xc = 'lda,vwn_rpa'\n",
    "charge = 0\n",
    "\n",
    "mol = gto.M(atom = atoms_from_ase(atoms), spin=0, basis=basis, charge = charge, parse_arg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6d715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_v(shape,eps):\n",
    "    bla=[np.random.random(shape) for _ in range(100)]\n",
    "    bla=(bla+bla.T)/2.0\n",
    "    return bla*eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773ed807",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RKS object of <class 'pyscf.dft.rks.RKS'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = scf.RKS(mol)\n",
    "mf.verbose = 0\n",
    "mf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4878687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_init = mf.make_rdm1\n",
    "o=mf.mo_occ\n",
    "c=mf.mo_coeff\n",
    "g_new=np.einsum('i,mi,ni->mn',o,c,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143e0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kin = mol.intor('int1e_kin')\n",
    "pot = mol.intor('int1e_nuc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1819ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = np.shape(pot)\n",
    "d_vext, d_gamma = [], []\n",
    "for e in np.linspace(start=0.01, stop=0.1,num=10):\n",
    "    perb, g_gamma = [], []\n",
    "    for n in np.arange(0,100,1):\n",
    "        d_pot = np.random.random(shape)\n",
    "        randpot1 = (d_pot+d_pot.T)/2.0 * e\n",
    "        randpot2 = randpot1 - np.trace(randpot1)* 1/len(g_new)\n",
    "        randpot = gaussian_filter(randpot2,1)\n",
    "        mf = scf.RKS(mol)\n",
    "        mf.verbose = 0\n",
    "        bla=mf.get_hcore\n",
    "        def my_get_hcore(mol):\n",
    "                hcore=bla(mol)\n",
    "                hcore+=randpot\n",
    "                return hcore\n",
    "        mf.get_hcore = my_get_hcore\n",
    "        mf.run(conv_tol=1.0e-12)\n",
    "        g_perb = mf.make_rdm1()\n",
    "        d_gama = g_new - g_perb\n",
    "        g_gamma.append(d_gama)\n",
    "        perb.append(randpot)\n",
    "    d_vext.append(perb)\n",
    "    d_gamma.append(g_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba9a58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('/home/valeria/Documents/DFTPY/project_2/DATA/d_ext_smooth', 'wb') as f:\n",
    "    pickle.dump(np.asarray(d_vext),f)\n",
    "with open('/home/valeria/Documents/DFTPY/project_2/DATA/g_gamma_smooth', 'wb') as f:\n",
    "    pickle.dump(np.asarray(d_gamma),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d332f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/valeria/Documents/DFTPY/project_2/DATA/d_ext_smooth', 'rb') as f:\n",
    "    d_vext = pickle.load(f)\n",
    "with open('/home/valeria/Documents/DFTPY/project_2/DATA/g_gamma_smooth', 'rb') as f:\n",
    "    d_gamma = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fabe662",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_vext = []\n",
    "D_gamma =[]\n",
    "for i in range(len(d_vext)):\n",
    "    for j in range(len(d_vext[1])):\n",
    "        D_vext.append(d_vext[i][j])\n",
    "        D_gamma.append(d_gamma[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69310051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "v = np.asarray(D_vext)\n",
    "vext = v.reshape(len(v), len(D_vext[1])*len(D_vext[1]))\n",
    "pca = PCA(n_components = 0.95)\n",
    "\n",
    "v_pca = pca.fit_transform(vext)\n",
    "\n",
    "dist = np.zeros((1000, 1000))\n",
    "for i in range(1000):\n",
    "    for j in range(i+1, 1000):\n",
    "        dist[i,j] = np.linalg.norm(v_pca[i,:] - v_pca[j,:])\n",
    "        dist[j,i] = dist[i,j]\n",
    "\n",
    "threshold = 0.01\n",
    "\n",
    "similar_indices = np.where(dist < threshold)\n",
    "\n",
    "# Remove duplicates\n",
    "unique_indices = []\n",
    "for i in range(len(similar_indices[0])):\n",
    "    if similar_indices[0][i] < similar_indices[1][i]:\n",
    "        unique_indices.append(similar_indices[0][i])\n",
    "\n",
    "# Remove similar matrices from the dataset\n",
    "unique_v = np.delete(v, unique_indices, axis=0)\n",
    "unique_D_vext = np.delete(D_vext, unique_indices, axis=0)\n",
    "unique_D_gamma = np.delete(D_gamma, unique_indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd857dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('/home/valeria/Documents/DFTPY/project_2/DATA/d_vext_pca', 'wb') as f:\n",
    "    pickle.dump(unique_v,f)\n",
    "with open('/home/valeria/Documents/DFTPY/project_2/DATA/g_gamma_pca', 'wb') as f:\n",
    "    pickle.dump(unique_D_gamma,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
